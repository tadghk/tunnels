{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./RECOTOOLS/')\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "from scipy import sparse\n",
    "import scipy\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from core import system_run, survey_metadata, run_collection, feature_collection\n",
    "import datalibrary\n",
    "import processor\n",
    "import systems.pelisystem\n",
    "from core import system_run, survey_metadata, run_collection\n",
    "from pandas_tools import *\n",
    "from mugrass.units import *\n",
    "from mugrass.voxelframe_meshgrid import *\n",
    "from mugrass.units import *\n",
    "from mugrass.voxelframe_meshgrid import *\n",
    "from mugrass.pixel_collection import *\n",
    "from mugrass.linear_solver_sparse import *\n",
    "from mugrass.muon_opacity import *\n",
    "from mugrass.units import *\n",
    "from mugrass.muon_opacity import *\n",
    "from mugrass.units import *\n",
    "\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in pixel dataframe calculated from survey data (made using 4_Convert_Features_to_Pixels.ipynb)\n",
    "pixels  = pixel_collection(pickle_path=\"pixel_dataframe.pxl\")\n",
    "\n",
    "# Load in custom voxel dataframe (made using 5_Build_Test_Grid.ipynb)\n",
    "voxels  = voxelframe_meshgrid(pickle_path=\"voxel_dataframe_masked.vxl\")\n",
    "\n",
    "# Load in weights matrix in CRS and CCS sparse formats, calculated by 6_Run_Embree_Calculator.py\n",
    "weights_crs=scipy.sparse.load_npz(f\"weights_masked_crs.npz\")\n",
    "weights_ccs=scipy.sparse.load_npz(f\"weights_masked_ccs.npz\")\n",
    "\n",
    "\n",
    "# Get the set of sparse vectors\n",
    "V_ccs=getattr(weights_ccs,\"data\")\n",
    "I_ccs=getattr(weights_ccs,\"indices\")\n",
    "S_ccs=getattr(weights_ccs,\"indptr\")\n",
    "\n",
    "V_crs=getattr(weights_crs,\"data\")\n",
    "I_crs=getattr(weights_crs,\"indices\")\n",
    "S_crs=getattr(weights_crs,\"indptr\")\n",
    "\n",
    "handler = linear_solver_sparse(voxels=voxels,pixels=pixels,v_crs=V_crs,i_crs=I_crs,s_crs=S_crs,v_ccs=V_ccs,i_ccs=I_ccs,s_ccs=S_ccs)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# View sample pixel FOV slices\n",
    "\n",
    "\n",
    "def crs_getrow(i,V_crs,I_crs,S_crs,S_ccs):\n",
    "    n_cols=len(S_ccs)-1\n",
    "    row=np.zeros(n_cols)\n",
    "    for v in range(S_crs[i],S_crs[i+1]):\n",
    "        row[I_crs[v]]=V_crs[v]\n",
    "    return row\n",
    "\n",
    "\n",
    "for i in range(len(pixels.df)):\n",
    "    #print(f\"pixel {i} out of {len(pixels.df)}\")\n",
    "    pixel_weight = (crs_getrow(i,V_crs,I_crs,S_crs,S_ccs)).transpose()\n",
    "\n",
    "    voxels.df[\"weight\"] = pixel_weight\n",
    "    print(f\"pixel {i} out of {len(pixels.df)}, x={pixels.df.x[i]}, combo={pixels.df.combo[i]}:\")\n",
    "    plt.hist2d(x=voxels.df.x, y=voxels.df.z, weights=voxels.df[\"weight\"]>0, bins=[len(np.unique(voxels.df.x)),len(np.unique(voxels.df.z))])\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    if i > 3: break\n",
    "    #break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare SART prerequisites\n",
    "\n",
    "from numba import jit\n",
    "@jit\n",
    "def Prepare_loopfunc(V_ccs,I_ccs,S_ccs,S_crs):\n",
    "\n",
    "    n_rows=len(S_crs)-1\n",
    "    n_voxels=len(S_ccs)-1\n",
    "\n",
    "    sart_f = np.zeros(n_voxels)\n",
    "\n",
    "    for i in range(n_voxels): \n",
    "        col=np.zeros(n_rows)\n",
    "        for s in range(S_ccs[i],S_ccs[i+1]):\n",
    "            col[I_ccs[s]]=V_ccs[s]\n",
    "        sart_f[i]=col.sum()\n",
    "        if sart_f[i] != 0:\n",
    "            sart_f[i]=1.0/sart_f[i]\n",
    "            #print(sart_f[i])    \n",
    "    return sart_f\n",
    "\n",
    "\n",
    "def SART_Prepare(handler):\n",
    "\n",
    "    n_rows=len(handler.data[\"pixels\"])\n",
    "\n",
    "    n_voxels=len(handler.data[\"voxels\"])\n",
    "\n",
    "    #weights_sq_vec=np.zeros(n_rows)\n",
    "\n",
    "    V_crs=handler.data[\"v_crs\"]\n",
    "    I_crs=handler.data[\"i_crs\"]\n",
    "    S_crs=handler.data[\"s_crs\"]\n",
    "\n",
    "    V_ccs=handler.data[\"v_ccs\"]\n",
    "    I_ccs=handler.data[\"i_ccs\"]  \n",
    "    S_ccs=handler.data[\"s_ccs\"]\n",
    "\n",
    "    sart_p = np.zeros(n_rows)\n",
    "    \n",
    "    for i in range(n_rows): \n",
    "        row=crs_getrow(i,V_crs,I_crs,S_crs,S_ccs)\n",
    "        #weights_sq_vec[i]=row.dot(row.transpose())\n",
    "        sart_p[i]=row.sum()\n",
    "        if sart_p[i] != 0:\n",
    "            sart_p[i]=1.0/sart_p[i]\n",
    "\n",
    "    \n",
    "    sart_f=Prepare_loopfunc(V_ccs,I_ccs,S_ccs,S_crs)\n",
    "    \n",
    "    handler.data[\"SART_P\"]=sart_p\n",
    "    handler.data[\"SART_F\"]=sart_f\n",
    "\n",
    "    #handler.data[\"weights_squared\"]=weights_sq_vec\n",
    "\n",
    "    print(\"SART_P\",handler.data[\"SART_P\"].shape, handler.data[\"SART_P\"].ndim)\n",
    "    print(\"SART_F\",handler.data[\"SART_F\"].shape, handler.data[\"SART_F\"].ndim)\n",
    "    \n",
    "\n",
    "\n",
    "handler.Prepare()\n",
    "\n",
    "SART_Prepare(handler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@jit\n",
    "def Predict_loopfunc(I_crs,S_crs,V_crs,voxelsdt):\n",
    "    n_pixels=len(S_crs)-1\n",
    "    prediction=np.zeros(n_pixels)\n",
    "    for m in range(n_pixels):\n",
    "        #print(f\"row {m} out of {n_pixels}\")\n",
    "        for v in range(S_crs[m],S_crs[m+1]):\n",
    "            prediction[m] += V_crs[v]*voxelsdt[I_crs[v]]\n",
    "    prediction[np.isnan(prediction)] = 0.0\n",
    "    return prediction\n",
    "\n",
    "@jit\n",
    "def Update_loopfunc(V_ccs,I_ccs,S_ccs,pixels,prediction,Pnp,Fnp):\n",
    "\n",
    "    n_voxels=len(S_ccs)-1\n",
    "\n",
    "    update=np.zeros(n_voxels)\n",
    "\n",
    "    for v in range(n_voxels):\n",
    "\n",
    "        delta_rho_v=0.\n",
    "\n",
    "        for s in range(S_ccs[v],S_ccs[v+1]):\n",
    "            m_nz=I_ccs[s]\n",
    "            #delta_rho_v += 1.0*(pixels[m_nz]-prediction[m_nz])*V_ccs[s]*Pnp[m_nz]\n",
    "            delta_rho_v += (pixels[m_nz]-prediction[m_nz])*V_ccs[s]*Pnp[m_nz]\n",
    "\n",
    "        delta_rho_v *= Fnp[v]\n",
    "        update[v]=delta_rho_v\n",
    "\n",
    "\n",
    "    return update * 0.9999\n",
    "\n",
    "def SART_Predict(handler):\n",
    "    #print(\"prediction start\")\n",
    "    voxelsdt = handler.data[\"voxels\"][\"value\"].copy()\n",
    "    V_crs=handler.data[\"v_crs\"]\n",
    "    I_crs=handler.data[\"i_crs\"]\n",
    "    S_crs=handler.data[\"s_crs\"]\n",
    "\n",
    "    V_ccs=handler.data[\"v_ccs\"]\n",
    "    I_ccs=handler.data[\"i_ccs\"]  \n",
    "    S_ccs=handler.data[\"s_ccs\"]\n",
    "    #n_pixels=len(S_crs)-1\n",
    "\n",
    "    #prediction=np.zeros(n_pixels)   \n",
    "    voxelsdt = handler.data[\"voxels\"][\"value\"].copy()\n",
    "    voxels=voxelsdt.to_numpy()\n",
    "\n",
    "    prediction=Predict_loopfunc(I_crs,S_crs,V_crs,voxels)\n",
    "\n",
    "    #print(\"prediction end\")\n",
    "    return prediction\n",
    "\n",
    "def SART_Update(handler):\n",
    "    prediction = SART_Predict(handler)\n",
    "\n",
    "    pixelsdt = handler.data[\"pixels\"][\"opacity\"].copy()    \n",
    "    \n",
    "    pixels=pixelsdt.to_numpy()\n",
    "\n",
    "    V_crs=handler.data[\"v_crs\"]\n",
    "    I_crs=handler.data[\"i_crs\"]\n",
    "    S_crs=handler.data[\"s_crs\"]\n",
    "\n",
    "    V_ccs=handler.data[\"v_ccs\"]\n",
    "    I_ccs=handler.data[\"i_ccs\"]  \n",
    "    S_ccs=handler.data[\"s_ccs\"]\n",
    "\n",
    "    Pnp = np.copy(handler.data['SART_P'])\n",
    "    Fnp = np.copy(handler.data['SART_F'])\n",
    "    \n",
    "    update=Update_loopfunc(V_ccs,I_ccs,S_ccs,pixels,prediction,Pnp,Fnp)\n",
    "\n",
    "    return update\n",
    "\n",
    "handler.Reset()\n",
    "\n",
    "\n",
    "voxels.df.loc[ voxels.df.zu <= voxels.df[\"DTM_height\"], 'value' ] = 2.65*g/cm3\n",
    "\n",
    "voxels.df.loc[ voxels.df.zu > voxels.df[\"DTM_height\"], 'value' ] = 0.0\n",
    "\n",
    "\n",
    "tunnel_height = 6*m # radius\n",
    "tunnel_width = 9*m/2 # radius\n",
    "\n",
    "voxels.df[\"in_tunnel\"] = ((voxels.df.y/tunnel_width)**2 + (voxels.df.z/tunnel_height)**2) < 1.0\n",
    "voxels.df.loc[voxels.df.in_tunnel, \"value\"] = 0.0\n",
    "\n",
    "\n",
    "voxels.df[\"initial_guess\"] = voxels.df[\"value\"]\n",
    "\n",
    "slice = voxels.df[ (np.abs(voxels.df.y) < 1*m)]\n",
    "\n",
    "plt.hist2d(x=slice.x/m, y=slice.z/m, weights=(slice.initial_guess/float(len(np.unique(slice.y))))/(g/cm3), bins=[len(np.unique(slice.x)),len(np.unique(slice.z))])\n",
    "plt.title(\"Initial guess\")\n",
    "plt.xlabel(\"Position [m]\")\n",
    "plt.ylabel(\"Elevation [m]\")\n",
    "plt.colorbar(label=\"Density (g/cm3)\")\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(x=pixels.df[\"x\"]/m,y=pixels.df[\"opacity\"]/(g/cm2))\n",
    "plt.xlabel(\"Position [m]\")\n",
    "plt.ylabel(\"Estimated Opacity [g/cm2]\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Call a SART Update and see how our solution looks\n",
    "n_iterations = 5\n",
    "\n",
    "\n",
    "# incorporate prior knowledge if desired\n",
    "use_priorknowledge=0\n",
    "\n",
    "pk_cutoff=1.25*g/cm3\n",
    "\n",
    "\n",
    "# Run SART\n",
    "for i in range(n_iterations):\n",
    "\n",
    "    print(f\"SART iter {i}\")\n",
    "    voxels.df.value += SART_Update(handler)\n",
    "    voxels.df.value[np.isnan(voxels.df.value)] = 2.65*g/cm3\n",
    "    voxels.df.loc[(voxels.df.value < 0), 'value']=0.0*g/cm3\n",
    "    voxels.df.loc[(voxels.df.value > 2.65*g/cm3), 'value']=2.65*g/cm3\n",
    "\n",
    "    # Force voxels below cut to zero\n",
    "    if (i % 1 == 0) & use_priorknowledge:\n",
    "        voxels.df.loc[(voxels.df.value < pk_cutoff) & (voxels.df.zu <= voxels.df[\"DTM_height\"]), 'value']=0.0*g/cm3\n",
    "\n",
    "   \n",
    "    \n",
    "\n",
    "# Draw 1m slice along crown\n",
    "slice = voxels.df[ (np.abs(voxels.df.y) < 1*m)] \n",
    "plt.hist2d(x=slice.x/1000, y=slice.z/1000, weights=(slice.value/float(len(np.unique(slice.y))))/(g/cm3), bins=[len(np.unique(slice.x)),len(np.unique(slice.z))])#,cmin=0,cmax=0.005)\n",
    "\n",
    "if use_priorknowledge:\n",
    "    plt.title(f\"Solution, {n_iterations} iterations, pk cut = {pk_cutoff/(g/cm3):.2f} g/cm3\")\n",
    "else:\n",
    "    plt.title(f\"Solution, {n_iterations} iterations\")\n",
    "\n",
    "plt.xlabel(\"Position [m]\")\n",
    "plt.ylabel(\"Elevation [m]\")\n",
    "plt.colorbar(label=\"Density (g/cm3)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "voxels.df.to_csv(\"sartoutput.csv\")   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
